{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/'\n",
    "TEST_SIZE = 0.1\n",
    "SEED = 42\n",
    "BATCH_SIZE = 1024\n",
    "DATA_SHUFFLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('data/' + 'users_preprocessed.csv')\n",
    "books = pd.read_csv('data/' + 'books_merged.csv')\n",
    "train = pd.read_csv('data/' + 'train_ratings.csv')\n",
    "test = pd.read_csv('data/' + 'test_ratings.csv')\n",
    "sub = pd.read_csv('data/' + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>location_city</th>\n",
       "      <th>location_state</th>\n",
       "      <th>location_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59744</th>\n",
       "      <td>262258</td>\n",
       "      <td>34.0</td>\n",
       "      <td>ohio_others</td>\n",
       "      <td>ohio</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   age location_city location_state location_country\n",
       "59744   262258  34.0   ohio_others           ohio              usa"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_url</th>\n",
       "      <th>language</th>\n",
       "      <th>summary</th>\n",
       "      <th>img_path</th>\n",
       "      <th>category_high</th>\n",
       "      <th>book_author</th>\n",
       "      <th>category</th>\n",
       "      <th>new_language</th>\n",
       "      <th>remove_country_code</th>\n",
       "      <th>book_author_over3</th>\n",
       "      <th>book_author_over5</th>\n",
       "      <th>book_author_over10</th>\n",
       "      <th>book_author_over50</th>\n",
       "      <th>book_author_over100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22678</th>\n",
       "      <td>0671754254</td>\n",
       "      <td>MY TEACHER GLOWS IN THE DARK (RACK SIZE)</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Aladdin</td>\n",
       "      <td>http://images.amazon.com/images/P/0671754254.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/0671754254.01.THUMBZZZ.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bruce Coville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>671754254</td>\n",
       "      <td>Bruce Coville</td>\n",
       "      <td>Bruce Coville</td>\n",
       "      <td>Bruce Coville</td>\n",
       "      <td>others</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             isbn                                book_title  \\\n",
       "22678  0671754254  MY TEACHER GLOWS IN THE DARK (RACK SIZE)   \n",
       "\n",
       "       year_of_publication publisher  \\\n",
       "22678               1991.0   Aladdin   \n",
       "\n",
       "                                                 img_url language summary  \\\n",
       "22678  http://images.amazon.com/images/P/0671754254.0...      NaN     NaN   \n",
       "\n",
       "                                img_path category_high    book_author  \\\n",
       "22678  images/0671754254.01.THUMBZZZ.jpg           NaN  Bruce Coville   \n",
       "\n",
       "      category new_language remove_country_code book_author_over3  \\\n",
       "22678      NaN           en           671754254     Bruce Coville   \n",
       "\n",
       "      book_author_over5 book_author_over10 book_author_over50  \\\n",
       "22678     Bruce Coville      Bruce Coville             others   \n",
       "\n",
       "      book_author_over100  \n",
       "22678              others  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def preprocess_age(users:pd.DataFrame):\n",
    "    if not isinstance(users, pd.DataFrame):\n",
    "        raise Exception(f\"Error at {inspect.currentframe().f_code.co_name}\\nnot pd.DataFrame\")\n",
    "    else:\n",
    "        # 남은 users['age'] 결측치\n",
    "        # global users['age']로 결측치 채우기\n",
    "        users = users['age'].fillna(users['age'].mean())\n",
    "        return users\n",
    "\n",
    "def preprocess_location(users:pd.DataFrame):\n",
    "    if not isinstance(users, pd.DataFrame):\n",
    "        raise Exception(f\"Error at {inspect.currentframe().f_code.co_name}\\nnot pd.DataFrame\")\n",
    "    else:\n",
    "    # location 결측치 채우기\n",
    "    # 우선 location_country 결측치를 최빈 country로 채우기\n",
    "        users['location_country'] = users['location_country'].fillna(users['location_country'].mode()[0])\n",
    "    # state 최빈값 대치\n",
    "        state_mode = users.groupby(['location_country'])['location_state'].agg(pd.Series.mode)\n",
    "        idx = users[(users['location_state'].isna())].index\n",
    "        for i in idx:\n",
    "            try:\n",
    "                tmp_country = users.loc[i, 'location_country']\n",
    "                if isinstance(state_mode[tmp_country], str):\n",
    "                    users.loc[i, 'location_state'] = state_mode[tmp_country]\n",
    "                else:\n",
    "                    users.loc[i, 'location_state'] = state_mode[tmp_country][0]\n",
    "            except:\n",
    "                pass\n",
    "    # city 최빈값 대치\n",
    "        city_mode1 = users.groupby(['location_country','location_state'])['location_city'].agg(pd.Series.mode)\n",
    "        city_mode2 = users.groupby(['location_state'])['location_city'].agg(pd.Series.mode)\n",
    "        city_mode3 = users.groupby(['location_country'])['location_city'].agg(pd.Series.mode)\n",
    "\n",
    "        idx = users[(users['location_city'].isna())].index\n",
    "        for i in idx:\n",
    "            tmp_state = users.loc[i, 'location_state']\n",
    "            tmp_country = users.loc[i, 'location_country']\n",
    "            try:\n",
    "                if isinstance(city_mode1[tmp_country,tmp_state], str):\n",
    "                    users.loc[i, 'location_city'] = city_mode1[tmp_country, tmp_state]\n",
    "                else:\n",
    "                    users.loc[i, 'location_city'] = city_mode1[tmp_country, tmp_state][0]\n",
    "            except:\n",
    "                try:\n",
    "                    if isinstance(city_mode2[tmp_state], str):\n",
    "                        users.loc[i, 'location_city'] = city_mode2[tmp_state]\n",
    "                    else:\n",
    "                        users.loc[i, 'location_city'] = city_mode2[tmp_state][0]\n",
    "                except:\n",
    "                    try:\n",
    "                        if isinstance(city_mode3[tmp_country], str):\n",
    "                            users.loc[i, 'location_city'] = city_mode3[tmp_country]\n",
    "                        else:\n",
    "                            users.loc[i, 'location_city'] = city_mode3[tmp_country][0]\n",
    "                    except:\n",
    "                        pass\n",
    "    # 너무 특이한 국가에서 사는 사람\n",
    "        users['location_state'] = users['location_state'] = users['location_state'].fillna(users['location_state'].mode()[0])\n",
    "        users['location_city'] = users['location_city'] = users['location_city'].fillna(users['location_city'].mode()[0])\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 책 전처리\n",
    "import inspect\n",
    "\n",
    "def preprocess_publisher(books:pd.DataFrame):\n",
    "    if not isinstance(books, pd.DataFrame):\n",
    "        raise Exception(f\"Error at {inspect.currentframe().f_code.co_name}\\nnot pd.DataFrame\")\n",
    "    else:\n",
    "    # isbn 첫 네자리 활용하여 publisher 전처리\n",
    "        publisher_dict=(books['publisher'].value_counts()).to_dict()\n",
    "        publisher_count_df= pd.DataFrame(list(publisher_dict.items()),columns = ['publisher','count'])\n",
    "        publisher_count_df = publisher_count_df.sort_values(by=['count'], ascending = False)\n",
    "\n",
    "        modify_list = publisher_count_df[publisher_count_df['count']>1].publisher.values\n",
    "        for publisher in modify_list:\n",
    "            try:\n",
    "                number = books[books['publisher']==publisher]['isbn'].apply(lambda x: x[:4]).value_counts().index[0]\n",
    "                right_publisher = books[books['isbn'].apply(lambda x: x[:4])==number]['publisher'].value_counts().index[0]\n",
    "                books.loc[books[books['isbn'].apply(lambda x: x[:4])==number].index,'publisher'] = right_publisher\n",
    "            except: \n",
    "                pass\n",
    "        return publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def users2idx(context_df, train_df, test_df, feature2idx:dict):\n",
    "    def age_map(x: int) -> int:\n",
    "        x = int(x)\n",
    "        if x < 20:\n",
    "            return 1\n",
    "        elif x >= 20 and x < 30:\n",
    "            return 2\n",
    "        elif x >= 30 and x < 40:\n",
    "            return 3\n",
    "        elif x >= 40 and x < 50:\n",
    "            return 4\n",
    "        elif x >= 50 and x < 60:\n",
    "            return 5\n",
    "        else:\n",
    "            return 6\n",
    "    if not isinstance(context_df, pd.DataFrame) or not isinstance(train_df, pd.DataFrame) or \\\n",
    "        not isinstance(test_df, pd.DataFrame):\n",
    "        raise Exception(f\"Error at {inspect.currentframe().f_code.co_name}\\nnot pd.DataFrame\")\n",
    "    else:\n",
    "        train_df['age'] = train_df['age'].fillna(int(train_df['age'].mean()))\n",
    "        train_df['age'] = train_df['age'].apply(age_map)\n",
    "        test_df['age'] = test_df['age'].fillna(int(test_df['age'].mean()))\n",
    "        test_df['age'] = test_df['age'].apply(age_map)\n",
    "        \n",
    "        for feature_name in ['city', 'state', 'country']:\n",
    "            idx_name = 'loc' + feature_name + '2idx'\n",
    "            feature_name = 'location_' + feature_name\n",
    "            \n",
    "            feature2idx[idx_name] = {v:k for k,v in enumerate(context_df[feature_name].unique())}\n",
    "            train_df[feature_name] = train_df[feature_name].map(feature2idx[idx_name])\n",
    "            test_df[feature_name] = test_df[feature_name].map(feature2idx[idx_name])\n",
    "        \n",
    "        return feature2idx, train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def books2idx(context_df, train_df, test_df, features_name:list, feature2idx:dict):\n",
    "    if not isinstance(context_df, pd.DataFrame) or not isinstance(train_df, pd.DataFrame) or \\\n",
    "        not isinstance(test_df, pd.DataFrame):\n",
    "        raise Exception(f\"Error at {inspect.currentframe().f_code.co_name}\\nnot pd.DataFrame\")\n",
    "    else:\n",
    "        for feature_name in features_name:\n",
    "            idx_name = feature_name + '2idx'\n",
    "            feature2idx[idx_name] = {v:k for k,v in enumerate(context_df[feature_name].unique())}\n",
    "            train_df[feature_name] = train_df[feature_name].map(feature2idx[idx_name])\n",
    "            test_df[feature_name] = test_df[feature_name].map(feature2idx[idx_name])\n",
    "        return feature2idx, train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_context_data(users, books, ratings1, ratings2, features_name:list):\n",
    "    # publisher 전처리\n",
    "    books = preprocess_publisher(books)\n",
    "    \n",
    "    # age, location 전처리\n",
    "    users = preprocess_location(preprocess_age(users))\n",
    "    \n",
    "    ratings = pd.concat([ratings1, ratings2]).reset_index(drop=True)\n",
    "\n",
    "    # 인덱싱 처리된 데이터 조인\n",
    "    \"\"\"\n",
    "    users_preprocessed:\n",
    "        dataframe\n",
    "        user_id,age,location_city,location_state,location_country\n",
    "        \n",
    "    books_merged:\n",
    "        dataframe\n",
    "        isbn,book_title,year_of_publication,publisher,img_url,\n",
    "        language,summary,img_path,category_high,book_author,category,\n",
    "        new_language,remove_country_code,book_author_over3,book_author_over5,\n",
    "        book_author_over10,book_author_over50,book_author_over100\n",
    "    \"\"\"   \n",
    "    # user_id, isbn, age, city, state, country, category_high, publisher_4_digit, language, author_10\n",
    "    context_df = ratings.merge(users, on='user_id', how='left').merge(books[features_name], on='isbn', how='left')\n",
    "    train_df = ratings1.merge(users, on='user_id', how='left').merge(books[features_name], on='isbn', how='left')\n",
    "    test_df = ratings2.merge(users, on='user_id', how='left').merge(books[features_name], on='isbn', how='left')\n",
    "\n",
    "    # users 인덱싱\n",
    "    idx, train_df, test_df = users2idx(context_df, train_df, test_df)\n",
    "    \n",
    "    # books 인덱싱\n",
    "    idx, train_df, test_df = books2idx(context_df, train_df, test_df, idx)\n",
    "    \n",
    "    return idx, train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_data_load(args):\n",
    "    # user_id, isbn, age, city, state, country, category_high, publisher_4_digit, language, author_10\n",
    "    features_name = args.ADD_CONTEXT\n",
    "    \n",
    "    users = pd.read_csv(DATA_PATH + 'users_preprocessed.csv')\n",
    "    \"\"\"\n",
    "    books_merged:\n",
    "        dataframe\n",
    "        isbn,book_title,year_of_publication,publisher,img_url,\n",
    "        language,summary,img_path,category_high,book_author,category,\n",
    "        new_language,remove_country_code,book_author_over3,book_author_over5,\n",
    "        book_author_over10,book_author_over50,book_author_over100\n",
    "    \"\"\"\n",
    "    books = pd.read_csv(DATA_PATH + 'books_merged.csv')\n",
    "    train = pd.read_csv(DATA_PATH + 'train_ratings.csv')\n",
    "    test = pd.read_csv(DATA_PATH + 'test_ratings.csv')\n",
    "    sub = pd.read_csv(DATA_PATH + 'sample_submission.csv')\n",
    "\n",
    "    # 모든 유저\n",
    "    ids = pd.concat([train['user_id'], sub['user_id']]).unique()\n",
    "    # 모든 책\n",
    "    isbns = pd.concat([train['isbn'], sub['isbn']]).unique()\n",
    "    idx2user = {idx:id for idx, id in enumerate(ids)}\n",
    "    idx2isbn = {idx:isbn for idx, isbn in enumerate(isbns)}\n",
    "    user2idx = {id:idx for idx, id in idx2user.items()}\n",
    "    isbn2idx = {isbn:idx for idx, isbn in idx2isbn.items()}\n",
    "    \n",
    "    train['user_id'] = train['user_id'].map(user2idx)\n",
    "    sub['user_id'] = sub['user_id'].map(user2idx)\n",
    "    test['user_id'] = test['user_id'].map(user2idx)\n",
    "\n",
    "    train['isbn'] = train['isbn'].map(isbn2idx)\n",
    "    sub['isbn'] = sub['isbn'].map(isbn2idx)\n",
    "    test['isbn'] = test['isbn'].map(isbn2idx)\n",
    "    \n",
    "    idx, context_train, context_test = process_context_data(users, books, train, test, features_name)\n",
    "    field_dims = np.array([len(user2idx), len(isbn2idx), 6], dtype=np.uint32)\n",
    "    for idx_name in idx.keys():\n",
    "        field_dims = np.append(field_dims, len(idx[idx_name]))\n",
    "\n",
    "    data = {\n",
    "            'train':train,\n",
    "            'test':test.drop(['rating'], axis=1),\n",
    "            'field_dims':field_dims,\n",
    "            'users':users,\n",
    "            'books':books,\n",
    "            'sub':sub,\n",
    "            'idx2user':idx2user,\n",
    "            'idx2isbn':idx2isbn,\n",
    "            'user2idx':user2idx,\n",
    "            'isbn2idx':isbn2idx,\n",
    "            }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_data_split(args, data):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "                                                        data['train'].drop(['rating'], axis=1),\n",
    "                                                        data['train']['rating'],\n",
    "                                                        test_size=args.TEST_SIZE,\n",
    "                                                        random_state=args.SEED,\n",
    "                                                        shuffle=True\n",
    "                                                        )\n",
    "    data['X_train'], data['X_valid'], data['y_train'], data['y_valid'] = X_train, X_valid, y_train, y_valid\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_data_loader(args, data):\n",
    "    train_dataset = TensorDataset(torch.LongTensor(data['X_train'].values), torch.LongTensor(data['y_train'].values))\n",
    "    valid_dataset = TensorDataset(torch.LongTensor(data['X_valid'].values), torch.LongTensor(data['y_valid'].values))\n",
    "    test_dataset = TensorDataset(torch.LongTensor(data['test'].values))\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=args.BATCH_SIZE, shuffle=args.DATA_SHUFFLE)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=args.BATCH_SIZE, shuffle=args.DATA_SHUFFLE)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=args.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    data['train_dataloader'], data['valid_dataloader'], data['test_dataloader'] = train_dataloader, valid_dataloader, test_dataloader\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isbn                       0\n",
       "book_title                 0\n",
       "year_of_publication        0\n",
       "publisher                  0\n",
       "img_url                    0\n",
       "language               67227\n",
       "summary                67227\n",
       "img_path                   0\n",
       "category_high          68851\n",
       "book_author                0\n",
       "category               69461\n",
       "new_language            1100\n",
       "remove_country_code     1100\n",
       "book_author_over3          0\n",
       "book_author_over5          0\n",
       "book_author_over10         0\n",
       "book_author_over50         0\n",
       "book_author_over100        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id             0\n",
       "age                 0\n",
       "location_city       0\n",
       "location_state      0\n",
       "location_country    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dl_data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dl_data_split(data)\n",
    "data = dl_data_loader(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
